// Auto generated by utensor-cli

#include "context.hpp"
#include "MatrixOps.hpp"
#include "deep_mlp.hpp"
#include "ArrayOps.hpp"
#include "tensor.hpp"
#include "MathOps.hpp"
#include "tensorIdxImporter.hpp"
#include "NnOps.hpp"


void get_deep_mlp_ctx(Context& ctx, Tensor* input_0) {

{ // add tensor for placeholders
    ctx.add(input_0, "x:0", 2);
}
{
    TensorIdxImporter t_import;
    ctx.add(t_import.int_import("/fs/constants/deep_mlp/Layer1_MatMul_eightbit_x_reshape_dims_0.idx"),
            "Layer1/MatMul_eightbit/x/reshape_dims:0",
            5);
}
{
    ctx.add(new RamTensor<float>(), "Layer1/MatMul_eightbit/x/reshape:0", 2);
    ctx.push(new ReshapeOp(), 
             { "x:0", "Layer1/MatMul_eightbit/x/reshape_dims:0" },
             { "Layer1/MatMul_eightbit/x/reshape:0" });
    ctx.eval();
}
{
    TensorIdxImporter t_import;
    ctx.add(t_import.int_import("/fs/constants/deep_mlp/Layer1_MatMul_eightbit_x_reduction_dims_0.idx"),
            "Layer1/MatMul_eightbit/x/reduction_dims:0",
            10);
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "Layer1/MatMul_eightbit/x/min:0", 1);
    ctx.push(new MinOp(), 
             { "Layer1/MatMul_eightbit/x/reshape:0", "Layer1/MatMul_eightbit/x/reduction_dims:0" },
             { "Layer1/MatMul_eightbit/x/min:0" });
    ctx.eval();
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "Layer1/MatMul_eightbit/x/max:0", 1);
    ctx.push(new MaxOp(), 
             { "Layer1/MatMul_eightbit/x/reshape:0", "Layer1/MatMul_eightbit/x/reduction_dims:0" },
             { "Layer1/MatMul_eightbit/x/max:0" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "Layer1/MatMul_eightbit/x/quantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "Layer1/MatMul_eightbit/x/quantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "Layer1/MatMul_eightbit/x/quantize:2", 1);
    ctx.push(new QuantizeV2Op(),
             {  "x:0",  "Layer1/MatMul_eightbit/x/min:0", "Layer1/MatMul_eightbit/x/max:0" },
             {  "Layer1/MatMul_eightbit/x/quantize:0",  "Layer1/MatMul_eightbit/x/quantize:1", "Layer1/MatMul_eightbit/x/quantize:2" });
    ctx.eval();
}
{
    TensorIdxImporter t_import;
    ctx.add(t_import.ubyte_import("/fs/constants/deep_mlp/Layer1_Variable_quantized_const_0.idx"),
            "Layer1/Variable_quantized_const:0",
            1);
}
{
    TensorIdxImporter t_import;
    ctx.add(t_import.float_import("/fs/constants/deep_mlp/Layer1_Variable_quantized_min_0.idx"),
            "Layer1/Variable_quantized_min:0",
            1);
}
{
    TensorIdxImporter t_import;
    ctx.add(t_import.float_import("/fs/constants/deep_mlp/Layer1_Variable_quantized_max_0.idx"),
            "Layer1/Variable_quantized_max:0",
            1);
}
{
    ctx.add(new RamTensor<int>(), "Layer1/MatMul/eightbit:0", 2);
    ctx.add(new RamTensor<float>({1}), "Layer1/MatMul/eightbit:1", 2);
    ctx.add(new RamTensor<float>({1}), "Layer1/MatMul/eightbit:2", 2);
    ctx.push(new QntMatMulOp<uint8_t, uint8_t, int>(), 
             { "Layer1/MatMul_eightbit/x/quantize:0", "Layer1/MatMul_eightbit/x/quantize:1", "Layer1/MatMul_eightbit/x/quantize:2", "Layer1/Variable_quantized_const:0", "Layer1/Variable_quantized_min:0",  "Layer1/Variable_quantized_max:0" },
             { "Layer1/MatMul/eightbit:0", "Layer1/MatMul/eightbit:1",  "Layer1/MatMul/eightbit:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<float>({1}), "Layer1/MatMul/eightbit/requant_range:0", 1);
    ctx.add(new RamTensor<float>({1}), "Layer1/MatMul/eightbit/requant_range:1", 1);
    ctx.push(new Requantization_RangeOp(),
             { "Layer1/MatMul/eightbit:0", "Layer1/MatMul/eightbit:1", "Layer1/MatMul/eightbit:2" },
             { "Layer1/MatMul/eightbit/requant_range:0", "Layer1/MatMul/eightbit/requant_range:1" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "Layer1/MatMul/eightbit/requantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "Layer1/MatMul/eightbit/requantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "Layer1/MatMul/eightbit/requantize:2", 1);
    ctx.push(new RequantizeOp(),
             { "Layer1/MatMul/eightbit:0", "Layer1/MatMul/eightbit:1", "Layer1/MatMul/eightbit:2", "Layer1/MatMul/eightbit/requant_range:0", "Layer1/MatMul/eightbit/requant_range:1" },
             { "Layer1/MatMul/eightbit/requantize:0", "Layer1/MatMul/eightbit/requantize:1", "Layer1/MatMul/eightbit/requantize:2" });
    ctx.eval();
}
{
    TensorIdxImporter t_import;
    ctx.add(t_import.float_import("/fs/constants/deep_mlp/Layer1_Variable_1_0.idx"),
            "Layer1/Variable_1:0",
            2);
}
{
    ctx.add(new RamTensor<float>(), "Layer1/zscore_eightbit/Layer1/Variable_1/reshape:0", 2);
    ctx.push(new ReshapeOp(), 
             { "Layer1/Variable_1:0", "Layer1/MatMul_eightbit/x/reshape_dims:0" },
             { "Layer1/zscore_eightbit/Layer1/Variable_1/reshape:0" });
    ctx.eval();
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "Layer1/zscore_eightbit/Layer1/Variable_1/min:0", 1);
    ctx.push(new MinOp(), 
             { "Layer1/zscore_eightbit/Layer1/Variable_1/reshape:0", "Layer1/MatMul_eightbit/x/reduction_dims:0" },
             { "Layer1/zscore_eightbit/Layer1/Variable_1/min:0" });
    ctx.eval();
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "Layer1/zscore_eightbit/Layer1/Variable_1/max:0", 1);
    ctx.push(new MaxOp(), 
             { "Layer1/zscore_eightbit/Layer1/Variable_1/reshape:0", "Layer1/MatMul_eightbit/x/reduction_dims:0" },
             { "Layer1/zscore_eightbit/Layer1/Variable_1/max:0" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "Layer1/zscore_eightbit/Layer1/Variable_1/quantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "Layer1/zscore_eightbit/Layer1/Variable_1/quantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "Layer1/zscore_eightbit/Layer1/Variable_1/quantize:2", 1);
    ctx.push(new QuantizeV2Op(),
             {  "Layer1/Variable_1:0",  "Layer1/zscore_eightbit/Layer1/Variable_1/min:0", "Layer1/zscore_eightbit/Layer1/Variable_1/max:0" },
             {  "Layer1/zscore_eightbit/Layer1/Variable_1/quantize:0",  "Layer1/zscore_eightbit/Layer1/Variable_1/quantize:1", "Layer1/zscore_eightbit/Layer1/Variable_1/quantize:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "Layer1/zscore/eightbit:0", 2);
    ctx.push(new AddOp<uint8_t, uint8_t>(),
             { "Layer1/MatMul/eightbit/requantize:0", "Layer1/zscore_eightbit/Layer1/Variable_1/quantize:0", "Layer1/MatMul/eightbit/requantize:1", "Layer1/MatMul/eightbit/requantize:2", "Layer1/zscore_eightbit/Layer1/Variable_1/quantize:1", "Layer1/zscore_eightbit/Layer1/Variable_1/quantize:2" }, 
             { "Layer1/zscore/eightbit:0" });

    ctx.eval();
}
{
    ctx.add(new RamTensor<float>({1}), "Layer1/zscore/eightbit/requant_range:0", 1);
    ctx.add(new RamTensor<float>({1}), "Layer1/zscore/eightbit/requant_range:1", 1);
    ctx.push(new Requantization_RangeOp(),
             { "Layer1/zscore/eightbit:0", "Layer1/zscore/eightbit:1", "Layer1/zscore/eightbit:2" },
             { "Layer1/zscore/eightbit/requant_range:0", "Layer1/zscore/eightbit/requant_range:1" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "Layer1/zscore/eightbit/requantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "Layer1/zscore/eightbit/requantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "Layer1/zscore/eightbit/requantize:2", 1);
    ctx.push(new RequantizeOp(),
             { "Layer1/zscore/eightbit:0", "Layer1/zscore/eightbit:1", "Layer1/zscore/eightbit:2", "Layer1/zscore/eightbit/requant_range:0", "Layer1/zscore/eightbit/requant_range:1" },
             { "Layer1/zscore/eightbit/requantize:0", "Layer1/zscore/eightbit/requantize:1", "Layer1/zscore/eightbit/requantize:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "Layer1/Relu/eightbit:0", 1);
    ctx.add(new RamTensor<float>({1}), "Layer1/Relu/eightbit:1", 1);
    ctx.add(new RamTensor<float>({1}), "Layer1/Relu/eightbit:2", 1);
    ctx.push(new ReluOp<uint8_t, float, uint8_t>(), 
             { "Layer1/zscore/eightbit/requantize:0", "Layer1/zscore/eightbit/requantize:1", "Layer1/zscore/eightbit/requantize:2" },
             { "Layer1/Relu/eightbit:0", "Layer1/Relu/eightbit:1", "Layer1/Relu/eightbit:2" });
    ctx.eval();
}
{
    TensorIdxImporter t_import;
    ctx.add(t_import.ubyte_import("/fs/constants/deep_mlp/Layer2_Variable_quantized_const_0.idx"),
            "Layer2/Variable_quantized_const:0",
            1);
}
{
    TensorIdxImporter t_import;
    ctx.add(t_import.float_import("/fs/constants/deep_mlp/Layer2_Variable_quantized_min_0.idx"),
            "Layer2/Variable_quantized_min:0",
            1);
}
{
    TensorIdxImporter t_import;
    ctx.add(t_import.float_import("/fs/constants/deep_mlp/Layer2_Variable_quantized_max_0.idx"),
            "Layer2/Variable_quantized_max:0",
            1);
}
{
    ctx.add(new RamTensor<int>(), "Layer2/MatMul/eightbit:0", 2);
    ctx.add(new RamTensor<float>({1}), "Layer2/MatMul/eightbit:1", 2);
    ctx.add(new RamTensor<float>({1}), "Layer2/MatMul/eightbit:2", 2);
    ctx.push(new QntMatMulOp<uint8_t, uint8_t, int>(), 
             { "Layer1/Relu/eightbit:0", "Layer1/Relu/eightbit:1", "Layer1/Relu/eightbit:2", "Layer2/Variable_quantized_const:0", "Layer2/Variable_quantized_min:0",  "Layer2/Variable_quantized_max:0" },
             { "Layer2/MatMul/eightbit:0", "Layer2/MatMul/eightbit:1",  "Layer2/MatMul/eightbit:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<float>({1}), "Layer2/MatMul/eightbit/requant_range:0", 1);
    ctx.add(new RamTensor<float>({1}), "Layer2/MatMul/eightbit/requant_range:1", 1);
    ctx.push(new Requantization_RangeOp(),
             { "Layer2/MatMul/eightbit:0", "Layer2/MatMul/eightbit:1", "Layer2/MatMul/eightbit:2" },
             { "Layer2/MatMul/eightbit/requant_range:0", "Layer2/MatMul/eightbit/requant_range:1" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "Layer2/MatMul/eightbit/requantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "Layer2/MatMul/eightbit/requantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "Layer2/MatMul/eightbit/requantize:2", 1);
    ctx.push(new RequantizeOp(),
             { "Layer2/MatMul/eightbit:0", "Layer2/MatMul/eightbit:1", "Layer2/MatMul/eightbit:2", "Layer2/MatMul/eightbit/requant_range:0", "Layer2/MatMul/eightbit/requant_range:1" },
             { "Layer2/MatMul/eightbit/requantize:0", "Layer2/MatMul/eightbit/requantize:1", "Layer2/MatMul/eightbit/requantize:2" });
    ctx.eval();
}
{
    TensorIdxImporter t_import;
    ctx.add(t_import.float_import("/fs/constants/deep_mlp/Layer2_Variable_1_0.idx"),
            "Layer2/Variable_1:0",
            2);
}
{
    ctx.add(new RamTensor<float>(), "Layer2/zscore_eightbit/Layer2/Variable_1/reshape:0", 2);
    ctx.push(new ReshapeOp(), 
             { "Layer2/Variable_1:0", "Layer1/MatMul_eightbit/x/reshape_dims:0" },
             { "Layer2/zscore_eightbit/Layer2/Variable_1/reshape:0" });
    ctx.eval();
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "Layer2/zscore_eightbit/Layer2/Variable_1/min:0", 1);
    ctx.push(new MinOp(), 
             { "Layer2/zscore_eightbit/Layer2/Variable_1/reshape:0", "Layer1/MatMul_eightbit/x/reduction_dims:0" },
             { "Layer2/zscore_eightbit/Layer2/Variable_1/min:0" });
    ctx.eval();
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "Layer2/zscore_eightbit/Layer2/Variable_1/max:0", 1);
    ctx.push(new MaxOp(), 
             { "Layer2/zscore_eightbit/Layer2/Variable_1/reshape:0", "Layer1/MatMul_eightbit/x/reduction_dims:0" },
             { "Layer2/zscore_eightbit/Layer2/Variable_1/max:0" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "Layer2/zscore_eightbit/Layer2/Variable_1/quantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "Layer2/zscore_eightbit/Layer2/Variable_1/quantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "Layer2/zscore_eightbit/Layer2/Variable_1/quantize:2", 1);
    ctx.push(new QuantizeV2Op(),
             {  "Layer2/Variable_1:0",  "Layer2/zscore_eightbit/Layer2/Variable_1/min:0", "Layer2/zscore_eightbit/Layer2/Variable_1/max:0" },
             {  "Layer2/zscore_eightbit/Layer2/Variable_1/quantize:0",  "Layer2/zscore_eightbit/Layer2/Variable_1/quantize:1", "Layer2/zscore_eightbit/Layer2/Variable_1/quantize:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "Layer2/zscore/eightbit:0", 2);
    ctx.push(new AddOp<uint8_t, uint8_t>(),
             { "Layer2/MatMul/eightbit/requantize:0", "Layer2/zscore_eightbit/Layer2/Variable_1/quantize:0", "Layer2/MatMul/eightbit/requantize:1", "Layer2/MatMul/eightbit/requantize:2", "Layer2/zscore_eightbit/Layer2/Variable_1/quantize:1", "Layer2/zscore_eightbit/Layer2/Variable_1/quantize:2" }, 
             { "Layer2/zscore/eightbit:0" });

    ctx.eval();
}
{
    ctx.add(new RamTensor<float>({1}), "Layer2/zscore/eightbit/requant_range:0", 1);
    ctx.add(new RamTensor<float>({1}), "Layer2/zscore/eightbit/requant_range:1", 1);
    ctx.push(new Requantization_RangeOp(),
             { "Layer2/zscore/eightbit:0", "Layer2/zscore/eightbit:1", "Layer2/zscore/eightbit:2" },
             { "Layer2/zscore/eightbit/requant_range:0", "Layer2/zscore/eightbit/requant_range:1" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "Layer2/zscore/eightbit/requantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "Layer2/zscore/eightbit/requantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "Layer2/zscore/eightbit/requantize:2", 1);
    ctx.push(new RequantizeOp(),
             { "Layer2/zscore/eightbit:0", "Layer2/zscore/eightbit:1", "Layer2/zscore/eightbit:2", "Layer2/zscore/eightbit/requant_range:0", "Layer2/zscore/eightbit/requant_range:1" },
             { "Layer2/zscore/eightbit/requantize:0", "Layer2/zscore/eightbit/requantize:1", "Layer2/zscore/eightbit/requantize:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "Layer2/Relu/eightbit:0", 1);
    ctx.add(new RamTensor<float>({1}), "Layer2/Relu/eightbit:1", 1);
    ctx.add(new RamTensor<float>({1}), "Layer2/Relu/eightbit:2", 1);
    ctx.push(new ReluOp<uint8_t, float, uint8_t>(), 
             { "Layer2/zscore/eightbit/requantize:0", "Layer2/zscore/eightbit/requantize:1", "Layer2/zscore/eightbit/requantize:2" },
             { "Layer2/Relu/eightbit:0", "Layer2/Relu/eightbit:1", "Layer2/Relu/eightbit:2" });
    ctx.eval();
}
{
    TensorIdxImporter t_import;
    ctx.add(t_import.float_import("/fs/constants/deep_mlp/OuputLayer_Variable_0.idx"),
            "OuputLayer/Variable:0",
            2);
}
{
    ctx.add(new RamTensor<float>(), "OuputLayer/MatMul_eightbit/OuputLayer/Variable/reshape:0", 2);
    ctx.push(new ReshapeOp(), 
             { "OuputLayer/Variable:0", "Layer1/MatMul_eightbit/x/reshape_dims:0" },
             { "OuputLayer/MatMul_eightbit/OuputLayer/Variable/reshape:0" });
    ctx.eval();
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "OuputLayer/MatMul_eightbit/OuputLayer/Variable/min:0", 1);
    ctx.push(new MinOp(), 
             { "OuputLayer/MatMul_eightbit/OuputLayer/Variable/reshape:0", "Layer1/MatMul_eightbit/x/reduction_dims:0" },
             { "OuputLayer/MatMul_eightbit/OuputLayer/Variable/min:0" });
    ctx.eval();
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "OuputLayer/MatMul_eightbit/OuputLayer/Variable/max:0", 1);
    ctx.push(new MaxOp(), 
             { "OuputLayer/MatMul_eightbit/OuputLayer/Variable/reshape:0", "Layer1/MatMul_eightbit/x/reduction_dims:0" },
             { "OuputLayer/MatMul_eightbit/OuputLayer/Variable/max:0" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "OuputLayer/MatMul_eightbit/OuputLayer/Variable/quantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "OuputLayer/MatMul_eightbit/OuputLayer/Variable/quantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "OuputLayer/MatMul_eightbit/OuputLayer/Variable/quantize:2", 1);
    ctx.push(new QuantizeV2Op(),
             {  "OuputLayer/Variable:0",  "OuputLayer/MatMul_eightbit/OuputLayer/Variable/min:0", "OuputLayer/MatMul_eightbit/OuputLayer/Variable/max:0" },
             {  "OuputLayer/MatMul_eightbit/OuputLayer/Variable/quantize:0",  "OuputLayer/MatMul_eightbit/OuputLayer/Variable/quantize:1", "OuputLayer/MatMul_eightbit/OuputLayer/Variable/quantize:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<int>(), "OuputLayer/MatMul/eightbit:0", 2);
    ctx.add(new RamTensor<float>({1}), "OuputLayer/MatMul/eightbit:1", 2);
    ctx.add(new RamTensor<float>({1}), "OuputLayer/MatMul/eightbit:2", 2);
    ctx.push(new QntMatMulOp<uint8_t, uint8_t, int>(), 
             { "Layer2/Relu/eightbit:0", "Layer2/Relu/eightbit:1", "Layer2/Relu/eightbit:2", "OuputLayer/MatMul_eightbit/OuputLayer/Variable/quantize:0", "OuputLayer/MatMul_eightbit/OuputLayer/Variable/quantize:1",  "OuputLayer/MatMul_eightbit/OuputLayer/Variable/quantize:2" },
             { "OuputLayer/MatMul/eightbit:0", "OuputLayer/MatMul/eightbit:1",  "OuputLayer/MatMul/eightbit:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<float>({1}), "OuputLayer/MatMul/eightbit/requant_range:0", 1);
    ctx.add(new RamTensor<float>({1}), "OuputLayer/MatMul/eightbit/requant_range:1", 1);
    ctx.push(new Requantization_RangeOp(),
             { "OuputLayer/MatMul/eightbit:0", "OuputLayer/MatMul/eightbit:1", "OuputLayer/MatMul/eightbit:2" },
             { "OuputLayer/MatMul/eightbit/requant_range:0", "OuputLayer/MatMul/eightbit/requant_range:1" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "OuputLayer/MatMul/eightbit/requantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "OuputLayer/MatMul/eightbit/requantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "OuputLayer/MatMul/eightbit/requantize:2", 1);
    ctx.push(new RequantizeOp(),
             { "OuputLayer/MatMul/eightbit:0", "OuputLayer/MatMul/eightbit:1", "OuputLayer/MatMul/eightbit:2", "OuputLayer/MatMul/eightbit/requant_range:0", "OuputLayer/MatMul/eightbit/requant_range:1" },
             { "OuputLayer/MatMul/eightbit/requantize:0", "OuputLayer/MatMul/eightbit/requantize:1", "OuputLayer/MatMul/eightbit/requantize:2" });
    ctx.eval();
}
{
    TensorIdxImporter t_import;
    ctx.add(t_import.float_import("/fs/constants/deep_mlp/OuputLayer_Variable_1_0.idx"),
            "OuputLayer/Variable_1:0",
            2);
}
{
    ctx.add(new RamTensor<float>(), "OuputLayer/prediction_eightbit/OuputLayer/Variable_1/reshape:0", 2);
    ctx.push(new ReshapeOp(), 
             { "OuputLayer/Variable_1:0", "Layer1/MatMul_eightbit/x/reshape_dims:0" },
             { "OuputLayer/prediction_eightbit/OuputLayer/Variable_1/reshape:0" });
    ctx.eval();
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "OuputLayer/prediction_eightbit/OuputLayer/Variable_1/min:0", 1);
    ctx.push(new MinOp(), 
             { "OuputLayer/prediction_eightbit/OuputLayer/Variable_1/reshape:0", "Layer1/MatMul_eightbit/x/reduction_dims:0" },
             { "OuputLayer/prediction_eightbit/OuputLayer/Variable_1/min:0" });
    ctx.eval();
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "OuputLayer/prediction_eightbit/OuputLayer/Variable_1/max:0", 1);
    ctx.push(new MaxOp(), 
             { "OuputLayer/prediction_eightbit/OuputLayer/Variable_1/reshape:0", "Layer1/MatMul_eightbit/x/reduction_dims:0" },
             { "OuputLayer/prediction_eightbit/OuputLayer/Variable_1/max:0" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "OuputLayer/prediction_eightbit/OuputLayer/Variable_1/quantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "OuputLayer/prediction_eightbit/OuputLayer/Variable_1/quantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "OuputLayer/prediction_eightbit/OuputLayer/Variable_1/quantize:2", 1);
    ctx.push(new QuantizeV2Op(),
             {  "OuputLayer/Variable_1:0",  "OuputLayer/prediction_eightbit/OuputLayer/Variable_1/min:0", "OuputLayer/prediction_eightbit/OuputLayer/Variable_1/max:0" },
             {  "OuputLayer/prediction_eightbit/OuputLayer/Variable_1/quantize:0",  "OuputLayer/prediction_eightbit/OuputLayer/Variable_1/quantize:1", "OuputLayer/prediction_eightbit/OuputLayer/Variable_1/quantize:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "OuputLayer/prediction/eightbit:0", 2);
    ctx.push(new AddOp<uint8_t, uint8_t>(),
             { "OuputLayer/MatMul/eightbit/requantize:0", "OuputLayer/prediction_eightbit/OuputLayer/Variable_1/quantize:0", "OuputLayer/MatMul/eightbit/requantize:1", "OuputLayer/MatMul/eightbit/requantize:2", "OuputLayer/prediction_eightbit/OuputLayer/Variable_1/quantize:1", "OuputLayer/prediction_eightbit/OuputLayer/Variable_1/quantize:2" }, 
             { "OuputLayer/prediction/eightbit:0" });

    ctx.eval();
}
{
    ctx.add(new RamTensor<float>({1}), "OuputLayer/prediction/eightbit/requant_range:0", 1);
    ctx.add(new RamTensor<float>({1}), "OuputLayer/prediction/eightbit/requant_range:1", 1);
    ctx.push(new Requantization_RangeOp(),
             { "OuputLayer/prediction/eightbit:0", "OuputLayer/prediction/eightbit:1", "OuputLayer/prediction/eightbit:2" },
             { "OuputLayer/prediction/eightbit/requant_range:0", "OuputLayer/prediction/eightbit/requant_range:1" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "OuputLayer/prediction/eightbit/requantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "OuputLayer/prediction/eightbit/requantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "OuputLayer/prediction/eightbit/requantize:2", 1);
    ctx.push(new RequantizeOp(),
             { "OuputLayer/prediction/eightbit:0", "OuputLayer/prediction/eightbit:1", "OuputLayer/prediction/eightbit:2", "OuputLayer/prediction/eightbit/requant_range:0", "OuputLayer/prediction/eightbit/requant_range:1" },
             { "OuputLayer/prediction/eightbit/requantize:0", "OuputLayer/prediction/eightbit/requantize:1", "OuputLayer/prediction/eightbit/requantize:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<float>(), "OuputLayer/prediction:0", 1);
    ctx.push(new DequantizeOp(), 
             { "OuputLayer/prediction/eightbit/requantize:0", "OuputLayer/prediction/eightbit/requantize:1", "OuputLayer/prediction/eightbit/requantize:2" },
             { "OuputLayer/prediction:0" });
    ctx.eval();
}
{
    TensorIdxImporter t_import;
    ctx.add(t_import.int_import("/fs/constants/deep_mlp/Loss_Sub_y_0.idx"),
            "Loss/Sub/y:0",
            1);
}
{
    ctx.add(new RamTensor<int>(), "Prediction/y_pred:0");
    ctx.push(new ArgMaxOp<float, int>(), 
             { "OuputLayer/prediction:0", "Loss/Sub/y:0" },
             { "Prediction/y_pred:0" });
}
}